{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ca99d5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# 1. Load dataset\n",
    "dataset = load_dataset(\"Samarth0710/bharatanatyam-mudra-dataset\")\n",
    "train_data = dataset[\"train\"]\n",
    "\n",
    "# 2. Setup MediaPipe\n",
    "mp_hands = mp.solutions.hands\n",
    "hands_detector = mp_hands.Hands(static_image_mode=True, max_num_hands=2)\n",
    "\n",
    "def extract_landmarks_dual(image):\n",
    "    \"\"\"Return concatenated landmarks for both hands (126 features: 2x21x3). \n",
    "       If hand missing, pad with zeros\"\"\"\n",
    "    results = hands_detector.process(np.array(image))\n",
    "    # Initialize left and right hands\n",
    "    hand_coords = [np.zeros(63), np.zeros(63)]  # 21x3 per hand\n",
    "    if results.multi_hand_landmarks and results.multi_handedness:\n",
    "        for idx, handLms in enumerate(results.multi_hand_landmarks):\n",
    "            landmarks = [coord for l in handLms.landmark for coord in (l.x, l.y, l.z)]\n",
    "            if results.multi_handedness[idx].classification[0].label == \"Left\":\n",
    "                hand_coords[0] = np.array(landmarks)\n",
    "            else:\n",
    "                hand_coords[1] = np.array(landmarks)\n",
    "    return np.concatenate(hand_coords)\n",
    "\n",
    "# 3. Process dataset subset\n",
    "all_data = []\n",
    "labels = []\n",
    "\n",
    "classes = list(set(train_data[\"label\"]))\n",
    "for cls in tqdm(classes, desc=\"Extracting landmarks\"):\n",
    "    samples = [s for s in train_data if s[\"label\"] == cls]\n",
    "    subset = random.sample(samples, max(1, len(samples)//4))\n",
    "    for s in subset:\n",
    "        image = s[\"image\"].convert(\"RGB\")\n",
    "        landmarks = extract_landmarks_dual(image)\n",
    "        if landmarks is not None:\n",
    "            all_data.append(landmarks)\n",
    "            labels.append(cls)\n",
    "\n",
    "# 4. Save to CSV\n",
    "df = pd.DataFrame(all_data)\n",
    "df[\"label\"] = labels\n",
    "df.to_csv(\"mudra_landmarks_dual.csv\", index=False)\n",
    "print(f\"Extracted landmarks from {len(df)} samples.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a578335",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "# Load landmark data\n",
    "data = pd.read_csv(\"mudra_landmarks_dual.csv\")\n",
    "X = data.drop(\"label\", axis=1)\n",
    "y = data[\"label\"]\n",
    "\n",
    "# Split and train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model = RandomForestClassifier(n_estimators=200, max_depth=20)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "preds = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, preds))\n",
    "print(classification_report(y_test, preds))\n",
    "\n",
    "# Save model\n",
    "joblib.dump(model, \"mudra_classifier_dual.pkl\")\n",
    "print(\"Model saved as mudra_classifier_dual.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
